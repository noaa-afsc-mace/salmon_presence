""" 
Runs the given quantification method on all videos and detections in the PRESENCE_DATA_PATH

Output:
    - A folder in "EXPERIMENTS_PATH" with the name "quantification_method-detection_source-confidence_threshold-min_presence_length"
        - If the quantification method doesn't use one of the arguments, it will not be included in the name
        - The folder will contain:
            - results.txt, with relevant results including overall precision and recall and precision and recall for each video
            - Graphs of presence data for each video. These vary depending on the quantification method


NOTE:
    - Detection data is not generated by this file. Use generate_detections.py to generate detection data in the correct format
    - The true floor for detection confidence is determined by `detection/model_info.json`

usage: 
salmost.py [-h] [-d DETECTION_SOURCE] [-c CONFIDENCE_THRESHOLD] [-p MIN_PRESENCE_THRESHOLD] [-f MIN_DETS_PER_FRAME]

arguments:
-h, --help            
                Show this help message and exit.
-d, --detection_source
                Name of detections to use. Must match the name of a folder in DETECTION_DATA_PATH
-c, --confidence_threshold
                Confidence threshold for detections.
-p, --min_presence_threshold
                Minimum number of frames for a presence to be considered. Shorter presences will be ignored.
-f, --min_dets_per_frame
                Minimum number of detections per frame to be considered. Shorter presences will be ignored.
"""

import os
import argparse
import glob
import cv2
import pandas as pd
from tqdm import tqdm
import pickle

from quantifying.DetectNum import DetectNum
from utils.data_writer import write_vid_data, write_tow_data, write_overall_data
from utils.visualize import visualize_tows

# ---- take a look at these ----
DEFAULT_DETECTION_SOURCE = "yolo_11_salmon-only_best_clips"
DETECTION_DATA_PATH = "/path/to/detection/directory/" # update this for your detections
PICKLED_DETECTION_DATA_PATH = "/path/to/pickled/detections/directory/" # update this for your detections
VIDEO_PATH = "/path/to/videos/presence_videos" # update this for your videos
EXPERIMENT_PATH = "quantifying_data/experiments/"
PRESENCE_DATA_PATH = "quantifying_data/presence_data/all_presence_data"
# ---- thanks ----


DETECTION_SOURCES = list(map(lambda x: x.split("/")[-1], glob.glob(os.path.join(DETECTION_DATA_PATH, "*"))))
RESULTS_COLUMNS = ["vid_name", "tow", "vid_presence_precision", "vid_presence_recall", "vid_num_predicted", "vid_num_gt", "vid_mse", "true_positives", \
                "false_positives", "false_negatives", "individual_recall", "proportion_saved_frames", "num_included_frames", \
                "saved_frames", "num_instances", "num_detected", "vid_frames", "num_gt_frames"]
PRESENCE_RESULTS_COLUMNS = ["name", "avg_detections_per_frame", "caught", "length (frames)"]

parser = argparse.ArgumentParser(description="Quantifies salmon")
parser.add_argument(
    "-d",
    "--detection_source",
    choices=DETECTION_SOURCES,
    help="Detection source. Must match the name of a folder in detections/",
    type=str,
    default=DEFAULT_DETECTION_SOURCE,
)
parser.add_argument(
    "-c",
    "--confidence_threshold",
    help="Confidence threshold for detections. Inclusive. NOTE: all detectors have a floor of 0.5",
    type=float,
    default=0.2,
)
parser.add_argument(
    "-p",
    "--min_presence_threshold",
    help="Minimum number of frames for a presence to be considered. Inclusive. Shorter presences will be ignored.",
    type=int,
    default=2,
)
parser.add_argument(
    "-f",
    "--min_dets_per_frame",
    help="Minimum number of detections per frame to be considered. Inclusive. Shorter presences will be ignored.",
    type=int,
    default=1,
)

def main(confidence_threshold, min_presence_length, min_dets_per_frame, experiment_results_path, detections_source):
    """
    Runs quantification for given method

    Args:
        confidence_threshold: min threshold for detection confidence
        min_dets_per_frame: min dets per frame
        experiment_results_path: path to save results
        detections_source: name of detection model
    """

    results = []
    presence_prediction_data_dict =  {} # {vid_name: [num_vid_frames, presence_frames]}
    gt_presence_data_dict = {} # {vid_name: [num_vid_frames, presence_frames]}
    # get all file names, they should be complete paths
    files_to_eval = glob.glob(os.path.join(PRESENCE_DATA_PATH, '*.csv'))
    # loop through files
    for i in tqdm(range(len(files_to_eval))):
        vid_name = os.path.basename(files_to_eval[i]).split(".")[0]
        tow = int(vid_name[1:3])
        vid_path = os.path.join(VIDEO_PATH, vid_name + ".MOV")
        detection_file = os.path.join(PICKLED_DETECTION_DATA_PATH, detections_source, f"{vid_name}.pickle")
        # get num frames in video
        vid = cv2.VideoCapture(vid_path)
        vid_frames = int(vid.get(cv2.CAP_PROP_FRAME_COUNT))
        vid.release()

        # create quantifier
        quantifier = DetectNum("detect_num", confidence_threshold, min_presence_length, min_dets_per_frame, vid_frames)

        # load detections
        # load pickled data
        with open(detection_file, 'rb') as handle:
            salmon_detections_dict = pickle.load(handle)
        # run quantification
        quantifier.quantify(salmon_detections_dict, vid_path)
        # load gt data
        gt_data = quantifier.load_gt(files_to_eval[i])
        # visualize
        quantifier.visualize(gt_data, experiment_results_path, vid_name)
        # evaluate
        vid_presence_precision, vid_presence_recall, vid_num_predicted, vid_num_gt, vid_mse, \
            true_positives, false_positives, false_negatives, num_gt_frames = quantifier.evaluate(gt_data)
        individual_recall, proportion_saved_frames, num_included_frames, saved_frames, num_instances, num_detected = quantifier.individual_recall(gt_data, vid_frames)
        # save results to df
        results.append([vid_name, tow, vid_presence_precision, vid_presence_recall, vid_num_predicted, vid_num_gt, vid_mse, true_positives, false_positives, false_negatives, \
                              individual_recall, proportion_saved_frames, num_included_frames, saved_frames, num_instances, num_detected, vid_frames, num_gt_frames])
        presence_prediction_data_dict[vid_name] = [vid_frames, set(quantifier.get_results_frames())]
        gt_presence_data_dict[vid_name] = [vid_frames, gt_data]

    results_df = pd.DataFrame(data=results, columns=RESULTS_COLUMNS)
    # visualize tows
    visualize_tows(presence_prediction_data_dict, gt_presence_data_dict, experiment_results_path)
    video_results_save_path = os.path.join(experiment_results_path, "video_results.txt")
    tow_results_save_path = os.path.join(experiment_results_path, "tow_results.txt")
    overall_results_save_path = os.path.join(experiment_results_path, "overall_results.txt")

    # save per-video results
    write_vid_data(results_df, video_results_save_path)
    # save per-tow results
    write_tow_data(results_df, tow_results_save_path)
    # save overall results
    write_overall_data(results_df, overall_results_save_path)

if __name__ == "__main__":
    quantification_method = "detect_num" # hard coding this because it's the only one we use in the paper
    args = parser.parse_args()
    detections_source = args.detection_source
    confidence_threshold = args.confidence_threshold
    min_presence_length = args.min_presence_threshold
    if min_presence_length < 1:
        print("Min presence length cannot be less than 1, setting to 1.")
        min_presence_length = 1
    min_dets_per_frame = args.min_dets_per_frame
    if min_dets_per_frame < 1:
        print("Min dets per frame cannot be less than 1. Setting to 1.")
        min_dets_per_frame = 1
    
    experiment_name = f"{quantification_method}-{detections_source}-{confidence_threshold}-{min_presence_length}-{min_dets_per_frame}"
    # check if experiment already exists, setup directories
    experiment_path = os.path.join(EXPERIMENT_PATH, experiment_name)
    if os.path.exists(experiment_path):
        print(f"Experiment {experiment_name} already exists. Overwriting...")
    else:
        os.mkdir(experiment_path)
    
    print(f"Running on the entire presence dataset")

    main(confidence_threshold, min_presence_length, min_dets_per_frame, experiment_path, detections_source)